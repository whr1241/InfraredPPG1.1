#!/usr/bin/env python
# -*- coding  : utf-8 -*-
# @Time       : 2022/3/9 22:19
# @Author     : wanghaoran
# @Site       : SCNU
# @File       : signal_tools.py
# @Description: åç»­ä¿¡å·å¤„ç†çš„å„ç§å‡½æ•°
# @Software   : PyCharm
import cv2
import matplotlib.pyplot as plt
import numpy as np
import scipy.linalg as sl  # åº”ç”¨äºçº¿æ€§ä»£æ•°ç¨‹åºé¢†åŸŸ
from scipy import signal
# from filterpy.kalman import KalmanFilter
# from filterpy.common import Q_discrete_white_noise
import pywt

"""
1ã€å·´ç‰¹æ²ƒæ–¯æ»¤æ³¢
ç§»åŠ¨å¹³å‡æ»¤æ³¢
æ»‘åŠ¨çª—å£æ»¤æ³¢ç®—æ³•
å…¨å±€è‡ªç›¸å…³æ»¤æ³¢
SPAå¹³æ»‘å…ˆéªŒè¶‹åŠ¿å»é™¤
å¹…å€¼æ»¤æ³¢
åŒæ€æ»¤æ³¢
é€‰æ‹©æœ€å…·æœ‰å‘¨æœŸæ€§çš„ä¿¡å·
FFTå˜æ¢
é¢‘åŸŸæœ€å¤§å€¼å¯¹åº”çš„é¢‘ç‡
å‡æ–¹æ ¹è¯¯å·®(RMSE)è®¡ç®—
"""


# å½“å‰ä½¿ç”¨
def fftTransfer(data, win_i, N=1024):
    """
    FFTå˜æ¢
    :return:
    TODO: å¯èƒ½éœ€è¦æ”¹è¿›ä¸€ä¸‹ï¼Œä»é¢‘è°±å›¾åˆ°åŠŸç‡è°±å›¾ã€‚å¥½åƒåˆä¸€æ ·
    """
    if len(data) < N:
        for _ in range(N - len(data)):  # è¡¥é›¶è¡¥è‡³Nç‚¹
            data.append(0)
    else:
        data = data[0:N]
    df = [30 / N * i for i in range(N)]  # é¢‘è°±åˆ†è¾¨ç‡ N=1024,dfä¹Ÿåº”è¯¥æ˜¯1024é•¿. 0åˆ°30
    fft_data = np.abs(np.fft.fft(data))  # typeæ˜¯array, shapeæ˜¯1024é•¿

    fft_data = fft_data.tolist()  # çºµåæ ‡

    # å‰120ä¸ªé‡Œé¢çš„æå€¼ç‚¹æ¨ªåæ ‡
    num_peak = signal.find_peaks(fft_data[0:120], distance=2) #distanceè¡¨æå¤§å€¼ç‚¹çš„è·ç¦»è‡³å°‘å¤§äºç­‰äº2ä¸ªæ°´å¹³å•ä½
    num_peak_list_X = num_peak[0].tolist()

    # å¾—åˆ°æå€¼ç‚¹çš„çºµåæ ‡
    num_peak_list_Y = []
    for i in num_peak_list_X:
        num_peak_list_Y.append(fft_data[i])

    # å–æœ€å¤§çš„äº”ä¸ªçºµåæ ‡
    num_peak_list_Y_final = sorted(num_peak_list_Y, reverse=True)[0:10]

    final_hr = []
    num_peak_list_X_final = []
    for i in num_peak_list_Y_final:    
        final_hr.append(df[fft_data[0:1024].index(i)]*60)
        num_peak_list_X_final.append(df[fft_data[0:1024].index(i)])  # æå€¼ç‚¹æ¨ªåæ ‡

    hr = df[fft_data[0:1024].index(max(fft_data[0:120]))]*60
    x = fft_data[0:1024].index(max(fft_data[0:120]))  # æœ€é«˜ç‚¹å¯¹æ€§çš„ç´¢å¼•
    # å½“ä¿¡å·å¾ˆæ¸…æ™°æ—¶ï¼Œä¸»å³°å¾ˆæ˜æ˜¾ï¼Œç›´æ¥åªå–ä¸»å³°å¥½äº†
    # TODOï¼šå‡å³°æœ‰æ—¶å€™ä¹Ÿä¼šå˜å¾—é«˜å‡ºçœŸå³°å¾ˆå¤šå€
    # TODOï¼šè¿˜æ˜¯åº”è¯¥æŒ‰ç…§åŠŸç‡æ¯”å€¼é˜ˆå€¼æ¥åˆ¤æ–­å§,è¿™é‡Œåº”è¯¥ç”¨ä¸€ä¸ªé‚»åŸŸçª—å£è®¡ç®—ï¼Œä¸åº”åªç”¨ä¸€ä¸ªé¢‘ç‡ç‚¹
    # TODOï¼šè¿™ä¸ªåˆ¤æ–­æ¡ä»¶è¿˜æ˜¯ä¸å¤ªè¡Œï¼Œæœ‰æ—¶å€™çœ‹ç€åƒä¸»å¯¼é¢‘ç‡ä½†å æ¯”åˆ°ä¸äº†20%ï¼Œå¦‚ä½•è¿›è¡Œåˆ¤æ–­ï¼Ÿ
    # if num_peak_list_Y_final[0]/sum(fft_data[0:512]) > 0.07:
    if sum(fft_data[(x-5):(x+5)])/sum(fft_data[0:512]) > 0.20:
        final_hr = [hr]
    print('æœ€å¤§å€¼çª—å£å æ€»åŠŸç‡æ¯”å€¼ï¼š', sum(fft_data[(x-5):(x+5)])/sum(fft_data[0:512]))
    # print('æœ€å¤§å€¼æ‰€åœ¨çª—å£åŠŸç‡å æ€»åŠŸç‡æ¯”å€¼ï¼š', num_peak_list_Y_final[0]/sum(fft_data[0:512]))

    # showä¸€ä¸‹
    plt.figure('FFT')
    plt.plot(df, fft_data)
    plt.axis([0, 5, 0, np.max(fft_data)*2])
    plt.title('çª—å£{}: Heart Rate estimate: {:.2f}'.format(win_i, hr))
    for ii in range(len(num_peak_list_Y_final)):  # ç”»å‡º5ä¸ªæå€¼ç‚¹
        plt.plot(num_peak_list_X_final[ii], num_peak_list_Y_final[ii],'*',markersize=10)
    plt.pause(0.1)	# pause 1 second
    plt.clf()		# clear the current figure
    return hr, final_hr



# å¯¹å…¨å±€ä¿¡å·æ‰¾å³°å€¼ç‚¹
def FindPeak(data, Plot=False):
    num_peak = signal.find_peaks(data, distance=2)
    num_peak = num_peak[0].tolist()
    if Plot:
        plt.plot(data)

# å¯¹çª—å£è¿›è¡Œæ£€æµ‹å¹¶plot,è¿”å›å³°å€¼æ•°é‡
def FindPeak_window(data, win_i):
    num_peak = signal.find_peaks(data, distance=10)
    num_peak = num_peak[0].tolist()
    sum_peak = len(num_peak)
    hr = sum_peak/10*60  # 10sçš„çª—å£
    
    plt.figure('FindPeak')
    plt.plot(data)
    for i in num_peak:
        plt.plot(i, data[i], '*')
    plt.title('window{}: Heart Rate estimate: {:.2f}'.format(win_i, hr))
    plt.pause(0.5)	# pause 1 second
    plt.clf()		# clear the current figure
    
    return hr



# å½’ä¸€åŒ–
def Normalization(data, Plot=False):
    """
    è¾“å…¥ï¼šarrayï¼Œè¡Œä¿¡å·
    è¾“å‡ºï¼š
    """
    data_final = np.zeros_like(data)
    for i in range(data.shape[0]):
        # data_final[i] = np.array(Z_ScoreNormalization(data[i]))
        data_final[i] = np.array(Arctan_Normalization(data[i]))
    if Plot:
        plt.figure("Normalization")
        N = data.shape[0]
        for n, s in enumerate(data):
            plt.subplot(N,1,n+1)
            plt.plot(s, 'g')
            plt.title("Normalization "+str(n))
            plt.xlabel("frames")
    return data_final

# å½’ä¸€åŒ–:Z-scoreæ ‡å‡†åŒ–
def Z_ScoreNormalization(x):
    mu = np.mean(x)
    sigma = np.std(x)
    x = (x - mu) / sigma;
    return x

# Min-Max Normalizationå½’ä¸€åŒ–
def Min_MaxNormalization(x):
    x = (x - np.min(x)) / (np.max(x) - np.min(x))
    return x

# arctanå½’ä¸€åŒ–
def Arctan_Normalization(data):
    """
    è¾“å…¥ï¼š
    è¾“å‡ºï¼š
    """
    """åæ­£åˆ‡å½’ä¸€åŒ–ï¼Œåæ­£åˆ‡å‡½æ•°çš„å€¼åŸŸå°±æ˜¯[-pi/2,pi/2]
    å…¬å¼ï¼šåæ­£åˆ‡å€¼ * (2 / pi)
    :return å€¼åŸŸ[-1,1]ï¼ŒåŸå§‹å¤§äº0çš„æ•°è¢«æ˜ å°„åˆ°[0,1]ï¼Œå°äº0çš„æ•°è¢«æ˜ å°„åˆ°[-1,0]
    """
    new_value = np.arctan(data) * (2 / np.pi)
    return new_value
    # data = [x*4 for x in data]  # ï¼Ÿ
    # data = np.arctan(data)
    # return data

# logå‡½æ•°è½¬æ¢å½’ä¸€åŒ–
def Log_Normalization(data):
    """
    è´Ÿå€¼æ€ä¹ˆåŠï¼Ÿ
    """
    data = np.log10(data)/np.log10(max(data))
    return data

def proportional_normalization(value):
    """æ¯”ä¾‹å½’ä¸€
    å…¬å¼ï¼šå€¼/æ€»å’Œ
    :return å€¼åŸŸ[0,1]  åˆä¸æ˜¯å…¨æ˜¯è´Ÿæ•°ï¼Ÿ
    """
    new_value = value / value.sum()
    return new_value



# å¹³æ»‘å…ˆéªŒè¶‹åŠ¿å»é™¤
def SPA(data, Plot=False):
    """
    è¾“å…¥æ˜¯ndarryï¼Œè¡Œä¿¡å·
    è¾“å‡ºè¿˜è¦ndarryï¼Œè¡Œä¿¡å·
    """
    data_final = np.zeros_like(data)
    for i in range(data.shape[0]):
        data_final[i] = np.array(SPA_detrending(data[i].tolist()))
    if Plot:
        plt.figure("SPA")
        N = data.shape[0]
        for n, spa in enumerate(data):
            plt.subplot(N,1,n+1)
            plt.plot(spa, 'g')
            plt.title("SPA "+str(n))
            plt.xlabel("frames")
    # plt.tight_layout()
    # x = np.arange(0, data.shape[1])
    # for i in range(data.shape[0]):
    #     plt.plot(x, data[i, :])  
    return data_final

def SPA_detrending(data, mu=1200):
    """
    å¹³æ»‘å…ˆéªŒæ³•å»é™¤è¶‹åŠ¿ (Smoothness Priors Approach, SPA) 
    åŸºäºæ­£åˆ™åŒ–æœ€å°äºŒä¹˜æ³•çš„å¹³æ»‘å…ˆéªŒæ³• http://www.cqvip.com/qk/97964x/201810/7000867680.html
    # èŠ¬å…°åº“å¥¥çš®å¥¥å¤§å­¦çš„Karjalainenåšå£«æå‡ºçš„ä¸€ç§ä¿¡å·éçº¿æ€§å»è¶‹åŠ¿æ–¹æ³•ï¼šhttps://zhuanlan.zhihu.com/p/336228933
    :param mu: æ­£åˆ™åŒ–ç³»æ•°
    :return:
    è¾“å…¥æ˜¯ä¸€ç»´list
    """
    N = len(data)
    D = np.zeros((N - 2, N))
    for n in range(N - 2):
        D[n, n], D[n, n + 1], D[n, n + 2] = 1.0, -2.0, 1.0
    D = mu * np.dot(D.T, D)  # å†…ç§¯
    for n in range(len(D)):
        D[n, n] += 1.0
    L = sl.cholesky(D, lower=True)
    Y = sl.solve_triangular(L, data, trans='N', lower=True)
    y = sl.solve_triangular(L, Y, trans='T', lower=True)
    data -= y
    return data.tolist()



# å¸¦é€šæ»¤æ³¢
def BandPassFilter(data, Plot=False):
    """
    è¾“å…¥æ˜¯ndarryï¼Œè¡Œä¿¡å·
    è¾“å‡ºè¿˜è¦ndarryï¼Œè¡Œä¿¡å·
    """
    data_final = np.zeros_like(data)
    for i in range(data.shape[0]):
        data_final[i] = np.array(Filter(data[i].tolist()))
    if Plot:
        plt.figure("Filter")
        N = data.shape[0]
        for n, fil in enumerate(data):
            plt.subplot(N,1,n+1)
            plt.plot(fil, 'g')
            plt.title("Filter "+str(n))
            plt.xlabel("frames")
    # plt.tight_layout()
    # x = np.arange(0, data.shape[1])  
    # for i in range(data.shape[0]):
    #     plt.plot(x, data[i, :])  
    return data_final

def Filter(data):
    """
    å¸¦é€šæ»¤æ³¢å™¨ 0.667--2.5Hz
    è¿™é‡Œå‡è®¾é‡‡æ ·é¢‘ç‡ä¸º1000hz,ä¿¡å·æœ¬èº«æœ€å¤§çš„é¢‘ç‡ä¸º500hzï¼Œè¦æ»¤é™¤100hzä»¥ä¸‹ï¼Œ
    400hzä»¥ä¸Šé¢‘ç‡æˆåˆ†ï¼Œå³æˆªè‡³é¢‘ç‡ä¸º100ï¼Œ400hz,åˆ™wn1=2*100/1000=0.2ï¼ŒWn1=0.2
    wn2=2*400/1000=0.8ï¼ŒWn2=0.8ã€‚Wn=[0.2,0.8]
    :return:
    """
    wn1 = 2 * 0.7 / 30   # origin 0.667
    wn2 = 2 * 4.0 / 30
    b, a = signal.butter(N=8, Wn=[wn1, wn2], btype='bandpass')     # 8é˜¶
    data = signal.filtfilt(b, a, data)                        # dataä¸ºè¦è¿‡æ»¤çš„ä¿¡å·
    data = data.tolist()                                 # ndarray --> list
    return data



def Wavelet2(ppg):
    """
    å°æ³¢å»å™ª https://www.jianshu.com/p/74f8e6d35ad5
    """
    y = ppg
    x= range(len(y))
    coeffs = pywt.wavedec(y, 'db4', level=4)  # 4é˜¶å°æ³¢åˆ†è§£
    ya4 = pywt.waverec(np.multiply(coeffs, [1, 0, 0, 0, 0]).tolist(), 'db4')
    yd4 = pywt.waverec(np.multiply(coeffs, [0, 1, 0, 0, 0]).tolist(), 'db4')
    yd3 = pywt.waverec(np.multiply(coeffs, [0, 0, 1, 0, 0]).tolist(), 'db4')
    yd2 = pywt.waverec(np.multiply(coeffs, [0, 0, 0, 1, 0]).tolist(), 'db4')
    yd1 = pywt.waverec(np.multiply(coeffs, [0, 0, 0, 0, 1]).tolist(), 'db4')



def Wavelet(ppg, Plot=False):
    """
    å°æ³¢å»å™ª https://www.cnblogs.com/sggggr/p/12381164.html
    è¾“å…¥ï¼šlist
    è¾“å‡ºï¼šlist
    """
    index = []
    data = []
    for i in range(len(ppg) - 1):
        X = float(i)
        Y = float(ppg[i])
        index.append(X)
        data.append(Y)

    # Create wavelet object and define parameters
    w = pywt.Wavelet('db8')  # é€‰ç”¨Daubechies8å°æ³¢
    maxlev = pywt.dwt_max_level(len(data), w.dec_len)
    print("maximum level is " + str(maxlev))  # ?
    threshold = 0.01  # Threshold for filtering  å»å™ªé˜ˆå€¼

    # Decompose into wavelet components, to the level selected:
    coeffs = pywt.wavedec(data, 'db8', level=maxlev)  # å°†ä¿¡å·è¿›è¡Œå°æ³¢åˆ†è§£

    for i in range(1, len(coeffs)):
        coeffs[i] = pywt.threshold(coeffs[i], threshold * max(coeffs[i]))  # å°†å™ªå£°æ»¤æ³¢

    mintime = 0
    maxtime = mintime + len(data)

    datarec = pywt.waverec(coeffs, 'db8')  # å°†ä¿¡å·è¿›è¡Œå°æ³¢é‡æ„
    # ?ä¸ºä»€ä¹ˆå‘¢ï¼Ÿ ä¸ºä»€ä¹ˆè¿‡æ»¤æ‰çš„ä¿¡å·åè€Œæ˜¯å¥½çš„å‘¢ï¼Ÿ
    final_data = np.array(data[mintime:maxtime]) - np.array(datarec[mintime:maxtime])
    # plotä¸€ä¸‹
    if Plot:
        plt.figure('Wavelet')
        plt.plot(data)
    return final_data.tolist()



class KalmanFilter(object):
    """
    https://github.com/zziz/kalman-filter
    """
    def __init__(self, F = None, B = None, H = None, Q = None, R = None, P = None, x0 = None):

        if(F is None or H is None):
            raise ValueError("Set proper system dynamics.")

        self.n = F.shape[1]
        self.m = H.shape[1]

        self.F = F
        self.H = H
        self.B = 0 if B is None else B
        self.Q = np.eye(self.n) if Q is None else Q
        self.R = np.eye(self.n) if R is None else R
        self.P = np.eye(self.n) if P is None else P
        self.x = np.zeros((self.n, 1)) if x0 is None else x0

    def predict(self, u = 0):
        self.x = np.dot(self.F, self.x) + np.dot(self.B, u)
        self.P = np.dot(np.dot(self.F, self.P), self.F.T) + self.Q
        return self.x

    def update(self, z):
        y = z - np.dot(self.H, self.x)
        S = self.R + np.dot(self.H, np.dot(self.P, self.H.T))
        K = np.dot(np.dot(self.P, self.H.T), np.linalg.inv(S))
        self.x = self.x + np.dot(K, y)
        I = np.eye(self.n)
        self.P = np.dot(np.dot(I - np.dot(K, self.H), self.P),
        	(I - np.dot(K, self.H)).T) + np.dot(np.dot(K, self.R), K.T)




# ç§»åŠ¨å¹³å‡æ»¤æ³¢
def M_A_Filter(data):
    """
    è¾“å…¥æ˜¯ndarryï¼Œè¡Œä¿¡å·
    è¾“å‡ºè¿˜è¦ndarryï¼Œè¡Œä¿¡å·
    """
    data_final = np.zeros_like(data)
    for i in range(data.shape[0]):
        data_final[i] = np.array(moveAverageFilter(data[i].tolist()))
    return data_final

# ç§»åŠ¨å¹³å‡æ»¤æ³¢, æ»¤æ³¢å™¨é•¿åº¦=3ï¼Œå¹¶å»ç›´æµï¼Œç›¸å½“äºæŠ‘åˆ¶é«˜é¢‘ï¼Ÿ
def moveAverageFilter(data):
    """
    è¾“å‡ºæ˜¯?
    è¾“å…¥æ˜¯list?
    """
    data1 = []
    j = 0
    while j < len(data):
        a = data[j] + data[j + 1] + data[j + 2] if j + 1 < (len(data) - 1) else data[j] * 3  # è¯­æ³•?ï¼Œæœ€åä¸¤ä¸ªå…ƒç´ ä¸å˜äº†
        data1.append(a / 3)
        j += 1
    data = data1
    # å»ç›´æµ
    direct_current = np.mean(data)  # å¯¹ç§»åŠ¨å¹³å‡æ»¤æ³¢åçš„æ•°æ®å–å¹³å‡
    data1 = [j - direct_current for j in data]  # ?
    data = data1
    return data



# æ»‘åŠ¨çª—å£æ»¤æ³¢ç®—æ³•ï¼Ÿå½’ä¸€åŒ–ï¼Œåœ¨0åæ ‡è½´é™„è¿‘éœ‡è¡
def sliding_window_demean(signal_values, num_windows):
    """
    è¾“å…¥ç±»å‹
    """
    window_size = int(round(len(signal_values) / num_windows))
    demeaned = np.zeros(signal_values.shape)
    for i in range(0, len(signal_values), window_size):
        if i + window_size > len(signal_values):
            window_size = len(signal_values) - i
        curr_slice = signal_values[i: i + window_size]
        demeaned[i:i + window_size] = curr_slice - np.mean(curr_slice)
    return demeaned



# å…¨å±€è‡ªç›¸å…³æ»¤æ³¢ï¼Œç”¨è‡ªç›¸å…³å¤„ç†åŒ…å«éšæœºå™ªå£°çš„ä¿¡å·ã€‚åº”è¯¥æ˜¯å‡ºè‡ªï¼š
# RealSense = Real Heart Rate: Illumination Invariant Heart Rate Estimation from Videos
def globalSelfsimilarityFilter(data):
    acf1 = np.correlate(data, data, mode='full')  # np.correlateç”¨äºè®¡ç®—ä¸¤ä¸ªä¸€ç»´åºåˆ—çš„äº’ç›¸å…³
    acf1 = acf1[len(data) - 1:]
    acf1 = acf1 / np.arange(len(data), 0, -1)
    acf1 = acf1 / acf1[0]
    data = acf1
    return data.tolist()



def amplitudeSelectiveFiltering(C_rgb, amax=0.002, delta=0.0001):
    """
    å¹…å€¼æ»¤æ³¢
    https://github.com/PartyTrix/Amplitude_selective_filtering
    Input: Raw RGB signals with dimensions 3xL, where the R channel is column 0
    Output:
    C = Filtered RGB-signals with added global mean,
    raw = Filtered RGB signals
    """
    C_rgb  = np.array(C_rgb)
    C_rgb = np.expand_dims(C_rgb, axis=1)

    s = C_rgb.shape[1]  # åˆ—æ•°ï¼Œå³æ—¶é—´åºåˆ—é•¿åº¦
    c = (1 / (np.mean(C_rgb, 1)))  # å¯¹å„è¡Œæ±‚å‡å€¼ï¼Œå†æ±‚å€’æ•°ï¼Œ æ˜¯ä¸€ç»´æ•°ç»„äº†ï¼Œé•¿åº¦ä¸º3

    # line 1
    c = np.transpose(np.array([c, ] * s)) * C_rgb - 1  # ç±»ä¼¼å¯¹æ¯ä¸ªæ—¶åºä¿¡å·è¿›è¡Œå½’ä¸€åŒ–

    # line 2
    f = abs(np.fft.fft(c, n=s, axis=1) / s)  # L -> C_rgb.shape[0],å¯¹æ¯ä¸€è¡Œåˆ†åˆ«è¿›è¡ŒFFTå˜æ¢ï¼Œå†é™¤ä»¥æ—¶åºä¿¡å·é•¿åº¦ï¼Œæœ€åå–ç»å¯¹å€¼

    # line 3
    w = (delta / np.abs(f[0, :]))  # F[0,:]  is the R-channel ï¼Œçº¢è‰²é€šé“å–å€’æ•°å†ä¹˜ä»¥ğŸ”ºï¼Œshapeå’Œtypeæ˜¯ï¼Ÿ

    # line 4
    w[np.abs(f[0, :] < amax)] = 1  # å°äºæœ€å¤§å€¼çš„å–1
    w = w.reshape([1, s])

    # line 5
    # ff = np.multiply(f, (np.tile(w, [3, 1])))  # å¤åˆ¶ä¸‰è¡Œï¼Œå†ä¸fé€å…ƒç´ ç›¸ä¹˜
    ff = np.multiply(f, (np.tile(w, [1, 1])))  # å¤åˆ¶ä¸‰è¡Œï¼Œå†ä¸fé€å…ƒç´ ç›¸ä¹˜

    # line 6
    c = np.transpose(np.array([(np.mean(C_rgb, 1)), ] * s)) * np.abs(np.fft.ifft(ff) + 1)  # å‡å€¼arrayä¸ FFTé€†å˜æ¢åŠ 1çš„å€¼ é€å…ƒç´ ç›¸ä¹˜
    raw = np.abs(np.fft.ifft(ff) + 1)

    return c.T, raw.T  # è½¬ç½®åå†è¾“å‡º



# é€‰æ‹©æœ€å…·æœ‰å‘¨æœŸæ€§çš„ä¿¡å·ï¼Œå³åŠŸç‡è°±å¯†åº¦å³°å€¼ç‚¹æ¨ªåæ ‡å¯¹åº”çš„é¢‘ç‡
def signal_selection(s):
    """
    å¿ƒç‡æ˜¯é€šè¿‡é€‰æ‹©æœ€å…·æœ‰å‘¨æœŸä¿¡å·çš„æœ€å¤§é¢‘ç‡æ¥è®¡ç®—çš„
    sï¼šåˆ—ä¿¡å·
    """
    fs = 30
    percentages = np.zeros(5)  # ä¸€ç»´åº¦ï¼Œ5ä¸ª0
    # æœ¬æ–‡åªåˆ†æäº†å‰5ä¸ªä¿¡å·
    for i in range(5):
        s_i = s[:, i]  # æœç„¶è¿˜æ˜¯åˆ—
        # è®¡ç®—æºä¿¡å·çš„åŠŸç‡è°±ï¼Œreturnçš„æ˜¯ä¸¤ä¸ªarrayï¼Œä¸çŸ¥é“ç»´åº¦ flattopæ˜¯çª—å£ç±»å‹ï¼Œspectrumæ˜¯åŠŸç‡è°±å¯†åº¦
        f, Pxx_spec = signal.periodogram(s_i, fs, 'flattop', scaling='spectrum')  # fçš„shapeä¸€ç»´lenï¼š251,èŒƒå›´0åˆ°15. Pxx_specä¹Ÿæ˜¯ï¼Œä½†å¥½åƒç«–ç€æ’åˆ—
        total_power = np.sum(Pxx_spec)  # è®¡ç®—æ€»åŠŸç‡
        # å¾—åˆ°æœ€å¤§åŠŸç‡çš„é¢‘ç‡åŠå…¶ä¸€æ¬¡è°æ³¢ï¼Œè¿˜æœ‰å®ƒä»¬çš„åæ ‡ç´¢å¼•
        [minPower, maxPower, minLoc, maxLoc] = cv2.minMaxLoc(Pxx_spec)  # ï¼Ÿ
        freqMaxPower = f[maxLoc[1]]  # maxLocæ˜¯tupleç±»å‹(0, 17)
        firstHarmonic = 2 * freqMaxPower
        firstHarmonicLoc = np.where(f == firstHarmonic)
        firstHarmonicPower = Pxx_spec[firstHarmonicLoc]
        #  è®¡ç®—æœ€å¤§é¢‘ç‡å æ€»åŠŸç‡çš„ç™¾åˆ†æ¯” å–å‰äº”ä¸ª
        percentages[i] = (maxPower + firstHarmonicPower) / total_power
    # åœ¨äº”ä¸ªåˆ†é‡ä¸­ï¼Œä»æœ€å…·å‘¨æœŸçš„ä¿¡å·æ¥è®¡ç®—BPM
    most_periodic_signal = np.argmax(percentages)  # è¿”å›æœ€å¤§å€¼ç´¢å¼•
    selected_signal = s[:, most_periodic_signal]  # æŒ‘å‡ºæ¥çš„æœ€å…·æœ‰å‘¨æœŸæ€§çš„ä¿¡å·
    f, Pxx_spec = signal.periodogram(selected_signal, fs, 'flattop', scaling='spectrum')
    [minVal, maxVal, minLoc, maxLoc] = cv2.minMaxLoc(Pxx_spec)  # è·å¾—æœ€å¤§åŠŸç‡æœ€å¤§å€¼çš„ç´¢å¼•ï¼Ÿ
    f_pulse = f[maxLoc[1]]
    bpm = 60.0 * f_pulse
    return bpm, selected_signal





# æ‰¾åˆ°é¢‘åŸŸæœ€å¤§å€¼å¯¹åº”çš„é¢‘ç‡ï¼Œæ‰¾æœ€å¤§ä¸¤ç§æ–¹æ³•ç»“æœç«Ÿç„¶ä¸ä¸€æ ·
# è¿™ä¸ªæ–¹æ³•è¾ƒå·®,å¯èƒ½æ˜¯fç²¾åº¦ä¸å¤Ÿ
def get_HR(f_signal, samplerate):  # f, pxx_specéƒ½æ˜¯251é•¿åº¦ä¸€ç»´ndarray
    f, pxx_spec = signal.periodogram(f_signal, samplerate, 'flattop', scaling='spectrum')
    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(pxx_spec)
    hr = f[max_loc[1]]
    bpm = 60.0 * hr
    return bpm


# ä¿¡å™ªæ¯”
def SNR(data):
    pass


# 12å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰è®¡ç®—
def compute_RMSE_every_n(signal1, signal2, sampling_time, mean_time):
    signal1_m, time_m = strided_mean(signal1, sampling_time, mean_time)
    signal2_m, _ = strided_mean(signal2, sampling_time, mean_time)

    RMSE = np.sqrt(np.mean((signal1_m - signal2_m) ** 2))
    rRMSE = np.mean(np.abs(signal1_m - signal2_m) / signal1_m)
    return RMSE, rRMSE


# å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰è®¡ç®—è°ƒç”¨
def strided_mean(signal,sampling_time, mean_time):
   block_len = np.ceil(mean_time/sampling_time)
   n_blocks = np.floor(signal.shape[0]/block_len)
   mean_sig = np.zeros([int(n_blocks),1])
   mean_t =np.arange(n_blocks)*mean_time
   for i in np.arange(n_blocks):
       mean_sig[int(i)]= signal[int(i*block_len):int((i+1)*block_len),...].mean()
   return mean_sig, mean_t




def show_signal(data, Plot=False):
    color_name = ['r', 'g', 'b', 'c', 'm']
    level_name = ['level_e_mean', 'level_0_mean', 'level_1_mean', 'level_2_mean', 'level_3_mean']
    if Plot:
        plt.figure("original regions_mean")
        x = np.arange(0, data.shape[1])  # è¿”å›ä¸€ä¸ªæœ‰ç»ˆç‚¹å’Œèµ·ç‚¹çš„å›ºå®šæ­¥é•¿çš„æ’åˆ—åšxè½´
        for i in range(data.shape[0]):
            # plt.plot(x, data[i, :], color=color_name[i], label=level_name[i])  # ç»˜åˆ¶ç¬¬iè¡Œ,å¹¶è´´å‡ºæ ‡ç­¾
            plt.plot(x, data[i, :])  # ç»˜åˆ¶ç¬¬iè¡Œ,å¹¶è´´å‡ºæ ‡ç­¾
        # plt.legend()
        plt.title("original regions_mean")
        # plt.show()
        # cv2.waitKey(10000)


# 2 å¹³æ»‘å…ˆéªŒæ³• (Smoothness Priors Approach, SPA)|param mu: æ­£åˆ™åŒ–ç³»æ•°|å»é™¤è¶‹åŠ¿ï¼Œç›¸å½“äºå»é™¤ä½é¢‘
# èŠ¬å…°åº“å¥¥çš®å¥¥å¤§å­¦çš„Karjalainenåšå£«æå‡ºçš„ä¸€ç§ä¿¡å·éçº¿æ€§å»è¶‹åŠ¿æ–¹æ³•ï¼šhttps://m.hanspub.org/journal/paper/28723
def SPA_detrending1(data, mu=1200):
    """
    å¹³æ»‘å…ˆéªŒæ³•å»é™¤è¶‹åŠ¿ (Smoothness Priors Approach, SPA),åº†éºŸåæ¥çš„
    :param mu: æ­£åˆ™åŒ–ç³»æ•°
    :return:
    """
    N = len(data)
    D = np.zeros((N - 2, N))
    for n in range(N - 2):
        D[n, n], D[n, n + 1], D[n, n + 2] = 1.0, -2.0, 1.0
    D = mu * np.dot(D.T, D)
    for n in range(len(D)):
        D[n, n] += 1.0
    L = sl.cholesky(D, lower=True)
    Y = sl.solve_triangular(L, data, trans='N', lower=True)
    y = sl.solve_triangular(L, Y, trans='T', lower=True)
    data -= y
    return data



# FFTå˜æ¢,è®¡ç®—è„‰æç‡å¹¶å±•ç¤ºç»“æœ
def fftTransfer1(filtered, framerate=30):  # è¾“å…¥æ•°æ®å’Œå¸§ç‡:ä¿¡å·æŠ½æ ·ç‡
    n = 512
    if len(filtered) < n:
        for _ in range(n - len(filtered)):  # è¡¥é›¶è¡¥è‡³Nç‚¹
            filtered.append(0)
    else:
        filtered = filtered[0:n]
    df = [framerate / n * i for i in range(n)]  # é¢‘è°±åˆ†è¾¨ç‡ï¼Ÿ
    fft_data = np.abs(np.fft.fft(filtered))

    hr = df[fft_data.tolist()[0:100].index(max(fft_data.tolist()[0:100]))] * 60  # å³°å€¼æ¨ªåæ ‡
    print('HR estimate:', hr)
    return hr